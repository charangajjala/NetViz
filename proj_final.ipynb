{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x18100042c40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PowerTransformer, QuantileTransformer, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import dash\n",
    "from dash import html, dcc\n",
    "from dash.dependencies import Input, Output\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.covariance import LedoitWolf\n",
    "import io\n",
    "import base64\n",
    "from sklearn.linear_model import ElasticNetCV, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('./sampled_df_float.csv')\n",
    "tsne_data = pd.read_csv('./tsne_final_result_2D.csv')\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Data Modification\n",
    "def apply_scaling(data, scaling_technique):\n",
    "    if scaling_technique == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scaling_technique == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaling_technique == 'power':\n",
    "        scaler = PowerTransformer()\n",
    "    elif scaling_technique == 'quantile':\n",
    "        scaler = QuantileTransformer(n_quantiles=100, output_distribution='normal')\n",
    "    elif scaling_technique == 'robust':\n",
    "        scaler = RobustScaler()\n",
    "    else:\n",
    "        raise ValueError('Invalid scaling technique provided')\n",
    "\n",
    "    if scaling_technique not in ['power', 'quantile', 'robust']:\n",
    "        features_to_normalize = data.drop(['attack_cat', 'label'], axis=1).columns\n",
    "        data[features_to_normalize] = scaler.fit_transform(data[features_to_normalize])\n",
    "    else:\n",
    "        if scaling_technique == 'power':\n",
    "            features_to_normalize = data.drop(['attack_cat', 'label'], axis=1).columns\n",
    "            data[features_to_normalize] = data[features_to_normalize] + 1e-6\n",
    "        features_to_normalize = data.drop(['attack_cat', 'label'], axis=1).columns\n",
    "        data[features_to_normalize] = scaler.fit_transform(data[features_to_normalize])\n",
    "\n",
    "    return data\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Location(id='url', refresh=False),\n",
    "    html.Div(id='app-content'),\n",
    "    # dcc.Dropdown(id='scaling-technique-pca', style={'display': 'none'}),\n",
    "    # dcc.Dropdown(id='scaling-technique-lda', style={'display': 'none'}),\n",
    "    dcc.RadioItems(id='plot-type-pca', style={'display': 'none'}),\n",
    "    dcc.Graph(id='pca-plot',style={'display': 'none'}),\n",
    "    dcc.RadioItems(id='plot-type-lda', style={'display': 'none'}),\n",
    "    dcc.Graph(id='lda-plot',style={'display': 'none'}),\n",
    "    dcc.Graph(id='tsne-plot',style={'display': 'none'}),\n",
    "    html.Div(id='heatmap-content',style={'display': 'none'}),\n",
    "    dcc.Graph(id='bar-plot',style={'display': 'none'}),\n",
    "    dcc.Graph(id='elastic-net-coef-plot',style={'display': 'none'}),\n",
    "    dcc.Graph(id='elastic-net-mse-plot',style={'display': 'none'}),\n",
    "    dcc.Graph(id='correration-matrix-plot',style={'display': 'none'}),\n",
    "    dcc.Graph(id='important-features-plot',style={'display': 'none'}),\n",
    "    dcc.Graph(id='kmeans-plot',style={'display': 'none'}),\n",
    "    dcc.Graph(id='random-forest-plot',style={'display': 'none'}),\n",
    "])\n",
    "\n",
    "\n",
    "def apply_pca(data, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_result = pca.fit_transform(data.drop(['attack_cat', 'label'], axis=1))\n",
    "    return pca_result\n",
    "\n",
    "def apply_lda(data, n_components):\n",
    "    lda = LinearDiscriminantAnalysis(n_components=n_components)\n",
    "    X = data.drop(['attack_cat', 'label'], axis=1)\n",
    "    y = data['attack_cat']\n",
    "    lda_result = lda.fit_transform(X, y)\n",
    "    return lda_result\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "        Output('app-content', 'children'), \n",
    "        [Input('url', 'pathname')],\n",
    ")\n",
    "def display_page(pathname):\n",
    "    if pathname == '/bv':\n",
    "        return basic_visulation_layout()\n",
    "    elif pathname == '/fs':\n",
    "        return feature_selection_layout()\n",
    "    elif pathname == '/civ':\n",
    "        return class_imbalance_page_layout()\n",
    "    elif pathname == '/pca':\n",
    "        return pca_layout()\n",
    "    elif pathname == '/tsne':\n",
    "        return tsne_layout()\n",
    "    elif pathname == '/heatmap':\n",
    "        return heatmap_layout()\n",
    "    elif pathname == '/barplot':\n",
    "        return barplot_layout()\n",
    "    elif pathname == '/elasticnet':\n",
    "        return elastic_net_layout()\n",
    "    elif pathname == '/lda':\n",
    "        return lda_layout()\n",
    "    elif pathname == '/kmeans':\n",
    "        return kmeans_layout()\n",
    "    elif pathname == '/randomforest':\n",
    "        return random_forest_layout()\n",
    "    else:\n",
    "        return home_layout()\n",
    "\n",
    "\n",
    "# PCA Layout\n",
    "def pca_layout():\n",
    "    return html.Div([\n",
    "        html.H1(\"PCA Plots\", style={'textAlign': 'center', 'font-family': 'Arial, sans-serif', 'color': '#3366cc', 'margin-bottom': '20px'}),\n",
    "        dcc.RadioItems(\n",
    "            id='plot-type-pca',\n",
    "            options=[\n",
    "                {'label': 'PCA 2D', 'value': 'pca2d'},\n",
    "                {'label': 'PCA 3D', 'value': 'pca3d'}\n",
    "            ],\n",
    "            labelStyle={'display': 'block'}\n",
    "        ),\n",
    "\n",
    "        # dcc.Dropdown(\n",
    "        #     id = 'scaling-technique-pca',\n",
    "        #     value='minmax',\n",
    "        #     placeholder='Select a scaling technique',\n",
    "        #     style={'display': 'none'}\n",
    "        # ),\n",
    "\n",
    "        html.Div(\n",
    "            dcc.Loading(\n",
    "                id='loading-pca',\n",
    "                children=dcc.Graph(id='pca-plot'),\n",
    "                type='circle'\n",
    "            )\n",
    "        )\n",
    "    ], style={'margin': 'auto', 'background-color': '#f8f8f8', 'padding': '20px', 'border-radius': '10px', 'box-shadow': '0px 0px 10px rgba(0, 0, 0, 0.1)'})\n",
    "\n",
    "# LDA Layout\n",
    "def lda_layout():\n",
    "    return html.Div([\n",
    "        html.H1(\"LDA Plots\", style={'textAlign': 'center', 'font-family': 'Arial, sans-serif', 'color': '#3366cc', 'margin-bottom': '20px'}),\n",
    "        dcc.RadioItems(\n",
    "            id='plot-type-lda',\n",
    "            options=[\n",
    "                {'label': 'LDA 2D', 'value': 'lda2d'},\n",
    "                {'label': 'LDA 3D', 'value': 'lda3d'}\n",
    "            ],\n",
    "            labelStyle={'display': 'block'}\n",
    "        ),\n",
    "\n",
    "        # dcc.Dropdown(\n",
    "        #     id = 'scaling-technique-pca',\n",
    "        #     value='minmax',\n",
    "        #     placeholder='Select a scaling technique',\n",
    "        #     style={'display': 'none'}\n",
    "        # ),\n",
    "\n",
    "        html.Div(\n",
    "            dcc.Loading(\n",
    "                id='loading-lda',\n",
    "                children=dcc.Graph(id='lda-plot'),\n",
    "                type='circle'\n",
    "            )\n",
    "        )\n",
    "    ], style={'margin': 'auto', 'background-color': '#f8f8f8', 'padding': '20px', 'border-radius': '10px', 'box-shadow': '0px 0px 10px rgba(0, 0, 0, 0.1)'})\n",
    "\n",
    "\n",
    "# PCA Callbacks\n",
    "@app.callback(\n",
    "    Output('pca-plot', 'figure'),\n",
    "    [Input('plot-type-pca', 'value'),\n",
    "    #  Input('scaling-technique-pca', 'value'),\n",
    "     Input('url', 'pathname')],\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def update_pca_plot(plot_type, pathname):\n",
    "    if pathname == '/pca':\n",
    "        if plot_type is None:\n",
    "            return dash.no_update\n",
    "        else:\n",
    "            scaling_technique = 'minmax'\n",
    "            scaled_data = apply_scaling(train_df.copy(), scaling_technique)\n",
    "            if plot_type == 'pca2d':\n",
    "                pca_result = apply_pca(scaled_data, 2)\n",
    "                plot_df = pd.DataFrame(data=pca_result, columns=['Component 1', 'Component 2'])\n",
    "                plot_df['Attack_Type'] = scaled_data['attack_cat']\n",
    "                fig_pca = px.scatter(plot_df, x='Component 1', y='Component 2', color='Attack_Type',\n",
    "                                        title='PCA 2D Plot with Attack Types', opacity=0.7)\n",
    "            else:\n",
    "                pca_result = apply_pca(scaled_data, 3)\n",
    "                plot_df = pd.DataFrame(data=pca_result, columns=['Component 1', 'Component 2', 'Component 3'])\n",
    "                plot_df['Attack_Type'] = scaled_data['attack_cat']\n",
    "                fig_pca = px.scatter_3d(plot_df, x='Component 1', y='Component 2', z='Component 3',\n",
    "                                        color='Attack_Type', title='PCA 3D Plot with Attack Types', opacity=0.7)\n",
    "                fig_pca.update_layout(width=800, height=600)\n",
    "\n",
    "            return fig_pca\n",
    "    else:\n",
    "        return dash.no_update\n",
    "    \n",
    "# LDA Callbacks\n",
    "# Similar to the PCA Callbacks\n",
    "@app.callback(\n",
    "    Output('lda-plot', 'figure'),\n",
    "    [Input('plot-type-lda', 'value'),\n",
    "    #  Input('scaling-technique-lda', 'value'),\n",
    "     Input('url', 'pathname')],\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def update_lda_plot(plot_type, pathname):\n",
    "    if pathname == '/lda':\n",
    "        if plot_type is None:\n",
    "            return dash.no_update\n",
    "        else:\n",
    "            scaling_technique = 'minmax'\n",
    "            scaled_data = apply_scaling(train_df.copy(), scaling_technique)\n",
    "            if plot_type == 'lda2d':\n",
    "                lda_result = apply_lda(scaled_data, 2)\n",
    "                plot_df = pd.DataFrame(data=lda_result, columns=['Component 1', 'Component 2'])\n",
    "                plot_df['Attack_Type'] = scaled_data['attack_cat']\n",
    "                fig_lda = px.scatter(plot_df, x='Component 1', y='Component 2', color='Attack_Type',\n",
    "                                        title='LDA 2D Plot with Attack Types', opacity=0.7)\n",
    "            else:\n",
    "                lda_result = apply_lda(scaled_data, 3)\n",
    "                plot_df = pd.DataFrame(data=lda_result, columns=['Component 1', 'Component 2', 'Component 3'])\n",
    "                plot_df['Attack_Type'] = scaled_data['attack_cat']\n",
    "                fig_lda = px.scatter_3d(plot_df, x='Component 1', y='Component 2', z='Component 3',\n",
    "                                        color='Attack_Type', title='LDA 3D Plot with Attack Types', opacity=0.7)\n",
    "            return fig_lda\n",
    "    else:\n",
    "        return dash.no_update\n",
    "\n",
    "# tsne layout\n",
    "def tsne_layout():\n",
    "    return html.Div(children=[\n",
    "        html.H1(\"t-SNE Plots\", style={'textAlign': 'center', 'font-family': 'Arial, sans-serif', 'color': '#3366cc', 'margin-bottom': '20px'}),\n",
    "        html.Div(\n",
    "            dcc.Loading(\n",
    "                id=\"loading-tsne\",\n",
    "                type=\"circle\",\n",
    "                children=dcc.Graph(id='tsne-plot')\n",
    "            )\n",
    "        )\n",
    "    ], style={'margin': 'auto', 'background-color': '#f8f8f8', 'padding': '20px', 'border-radius': '10px', 'box-shadow': '0px 0px 10px rgba(0, 0, 0, 0.1)'})\n",
    "\n",
    "# tsne callbacks\n",
    "@app.callback(\n",
    "        Output('tsne-plot','figure'),\n",
    "        [Input('url', 'pathname'),],\n",
    "        prevent_initial_call=True\n",
    ")\n",
    "def update_tsne_plot(pathname):\n",
    "    if pathname == '/tsne':\n",
    "        fig_tsne = px.scatter(tsne_data, x='t-SNE Component 1', y='t-SNE Component 2', color='Attack_Type',\n",
    "                                title='t-SNE 2D Plot with Attack Types', opacity=0.7)\n",
    "        return fig_tsne\n",
    "    else:\n",
    "        return dash.no_update\n",
    "\n",
    "# Mahalanobis Distance Calculation\n",
    "def calculate_mahalanobis_distances(data, attack_categories):\n",
    "    centroids = {}\n",
    "    for category in attack_categories:\n",
    "        data_subset = data[data['attack_cat'] == category]\n",
    "        centroid = data_subset.drop(['attack_cat', 'label'], axis=1).mean().values\n",
    "        centroids[category] = centroid\n",
    "    \n",
    "    lw = LedoitWolf()\n",
    "    covariance_matrix = lw.fit(data.drop(['attack_cat', 'label'], axis=1)).covariance_\n",
    "    \n",
    "    mahalanobis_distances = {}\n",
    "    for category1 in attack_categories:\n",
    "        for category2 in attack_categories:\n",
    "            if category1 != category2:\n",
    "                delta = centroids[category1] - centroids[category2]\n",
    "                m = np.dot(np.dot(delta, np.linalg.inv(covariance_matrix)), delta)\n",
    "                mahalanobis_distances[(category1, category2)] = np.sqrt(m)\n",
    "    \n",
    "    distance_matrix = pd.DataFrame(columns=attack_categories, index=attack_categories)\n",
    "    for category1 in attack_categories:\n",
    "        for category2 in attack_categories:\n",
    "            if category1 == category2:\n",
    "                distance_matrix.at[category1, category2] = 0.0\n",
    "            else:\n",
    "                distance_matrix.at[category1, category2] = mahalanobis_distances[(category1, category2)]\n",
    "    distance_matrix = distance_matrix.astype(float)\n",
    "    return distance_matrix\n",
    "\n",
    "# Heatmap Generation\n",
    "def generate_heatmap(data):\n",
    "    scaling_techniques = ['no_scaling', 'min_max', 'standard', 'quantile', 'robust', 'power']  # Include 'no_scaling'\n",
    "\n",
    "    assets_dir = os.path.join(os.getcwd(), 'assets')\n",
    "    os.makedirs(assets_dir, exist_ok=True)\n",
    "    \n",
    "    heatmap_divs = []\n",
    "    # Loop through scaling techniques\n",
    "    for scaling_technique in scaling_techniques:\n",
    "        # Check if the image file already exists\n",
    "        img_filename = os.path.join(assets_dir, f\"heatmap_{scaling_technique}.png\")\n",
    "        # img_filename = f\"heatmap_{scaling_technique}.png\"\n",
    "        title = \"\"\n",
    "        if os.path.exists(img_filename):\n",
    "            with open(img_filename, 'rb') as img_file:\n",
    "                img_src = 'data:image/png;base64,{}'.format(base64.b64encode(img_file.read()).decode())\n",
    "        else:\n",
    "            # If the image file doesn't exist, generate and save the heatmap\n",
    "            if scaling_technique == 'no_scaling':\n",
    "                scaled_train_df = data.copy()  # Create a copy of the original data without scaling\n",
    "            else:\n",
    "                if scaling_technique == 'min_max':\n",
    "                    scaler = MinMaxScaler()\n",
    "                elif scaling_technique == 'standard':\n",
    "                    scaler = StandardScaler()\n",
    "                elif scaling_technique == 'quantile':\n",
    "                    scaler = QuantileTransformer(n_quantiles=100, output_distribution='normal')\n",
    "                elif scaling_technique == 'robust':\n",
    "                    scaler = RobustScaler()\n",
    "                elif scaling_technique == 'power':\n",
    "                    scaler = PowerTransformer()\n",
    "                # Add conditions for other scaling techniques\n",
    "            \n",
    "                # Apply the respective scaler to the data\n",
    "                features_to_normalize = data.drop(['attack_cat', 'label'], axis=1).columns\n",
    "                scaled_train_df = data.copy()\n",
    "                if scaling_technique != 'power':\n",
    "                    scaled_train_df[features_to_normalize] = scaler.fit_transform(data[features_to_normalize])\n",
    "                else:\n",
    "                    scaled_train_df[features_to_normalize] = data[features_to_normalize] + 1e-6\n",
    "                    scaled_train_df[features_to_normalize] = scaler.fit_transform(scaled_train_df[features_to_normalize])\n",
    "\n",
    "            attack_categories = data['attack_cat'].unique()\n",
    "            distance_matrix = calculate_mahalanobis_distances(scaled_train_df, attack_categories)\n",
    "            \n",
    "            mask = np.triu(np.ones(distance_matrix.shape), k=1)\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(distance_matrix, cmap=\"RdYlGn\", annot=True, fmt=\".2f\", linewidths=0.5, mask=mask)\n",
    "            if scaling_technique == 'no_scaling':\n",
    "                title = \"Centroid Distance Heatmap without Scaling\"\n",
    "            else:\n",
    "                title = \"Centroid Distance Heatmap after \" + scaling_technique + \" scaling\"\n",
    "            plt.title(title)\n",
    "            \n",
    "            # Save the plot as a binary image\n",
    "            plt.savefig(img_filename, format='png')\n",
    "            \n",
    "            # Create HTML img element with base64 encoded image\n",
    "            with open(img_filename, 'rb') as img_file:\n",
    "                img_src = 'data:image/png;base64,{}'.format(base64.b64encode(img_file.read()).decode())\n",
    "            \n",
    "            plt.close()  # Close the plot to prevent display in the Dash app\n",
    "        \n",
    "        heatmap_divs.append(\n",
    "            html.Div([\n",
    "                html.H3(title),\n",
    "                html.Img(src=img_src, style={'width': '100%'})\n",
    "            ])\n",
    "        )\n",
    "\n",
    "    return heatmap_divs\n",
    "\n",
    "# heatmap callbacks\n",
    "@app.callback(\n",
    "    Output('heatmap-content', 'children'),\n",
    "    # Output('loading-heatmap', 'children'),\n",
    "    [Input('url', 'pathname'),],\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def update_heatmap(pathname):\n",
    "    if pathname == '/heatmap':\n",
    "        heatmap_divs = generate_heatmap(train_df)\n",
    "        heatmap_content = html.Div([\n",
    "            html.H1(\"Mahalanobis Distance Heatmaps\", style={'textAlign': 'center', 'font-family': 'Arial, sans-serif', 'color': '#3366cc', 'margin-bottom': '20px'}),\n",
    "            html.Div(heatmap_divs, style={'display': 'grid', 'grid-template-columns': 'repeat(3, 1fr)'})\n",
    "        ])\n",
    "        return heatmap_content\n",
    "    else:\n",
    "        return dash.no_update\n",
    "\n",
    "# heatmap layout\n",
    "def heatmap_layout():\n",
    "    return html.Div(\n",
    "        id='heatmap-content', style={'margin': 'auto', 'background-color': '#f8f8f8', 'padding': '20px', 'border-radius': '10px', 'box-shadow': '0px 0px 10px rgba(0, 0, 0, 0.1)'})\n",
    "\n",
    "# Barplot Layout\n",
    "def barplot_layout():\n",
    "    return html.Div([\n",
    "        html.H1(\"Attack Type Distribution\", style={'textAlign': 'center', 'font-family': 'Arial, sans-serif', 'color': '#3366cc', 'margin-bottom': '20px'}),\n",
    "        dcc.Loading(\n",
    "            id=\"loading-bar-plot\",\n",
    "            type=\"circle\",\n",
    "            children=[dcc.Graph(id='bar-plot')]\n",
    "        )\n",
    "    ], style={'margin': 'auto', 'background-color': '#f8f8f8', 'padding': '20px', 'border-radius': '10px', 'box-shadow': '0px 0px 10px rgba(0, 0, 0, 0.1)'})\n",
    "\n",
    "\n",
    "# Function to generate bar plot for attack type distribution\n",
    "def generate_attack_type_barplot(data):\n",
    "    attack_type_counts = data['attack_cat'].value_counts()\n",
    "    fig_bar = px.bar(\n",
    "        x=attack_type_counts.index, \n",
    "        y=attack_type_counts.values, \n",
    "        labels={'x': 'Attack Type', 'y': 'Count'}, \n",
    "        title='Distribution of Attack Types'\n",
    "    )\n",
    "    return fig_bar\n",
    "\n",
    "# Barplot Callbacks\n",
    "@app.callback(\n",
    "    Output('bar-plot','figure'),\n",
    "    [Input('url', 'pathname')],\n",
    "    # Having this True is making the calls unpredictable having\n",
    "    # it as False is making the calls predictable and no cache error\n",
    "    prevent_initial_call=False\n",
    ")\n",
    "def update_bar_plot(pathname):\n",
    "    if pathname == '/barplot':\n",
    "        bar_plot = generate_attack_type_barplot(train_df)\n",
    "        return bar_plot\n",
    "    else:\n",
    "        return dash.no_update\n",
    "\n",
    "# Home Layout\n",
    "def home_layout():\n",
    "    return html.Div([\n",
    "        html.H1(\"Welcome to the Home Page\", style={'font-family': 'Arial, sans-serif', 'color': '#3366cc'}),\n",
    "        html.P(\"Navigate to other pages using the links below:\", style={'font-family': 'Arial, sans-serif'}),\n",
    "        html.Br(),\n",
    "        dcc.Link('Basic Visualization', href='/bv', style={'display': 'block', 'text-decoration': 'none', 'color': '#3366cc', 'margin-bottom': '10px'}),\n",
    "        dcc.Link('Feature Selection', href='/fs', style={'display': 'block', 'text-decoration': 'none', 'color': '#3366cc', 'margin-bottom': '10px'}),\n",
    "        dcc.Link('Class Imbalance Visualization', href='/civ', style={'display': 'block', 'text-decoration': 'none', 'color': '#3366cc', 'margin-bottom': '10px'}),\n",
    "    ], style={'width': '60%', 'margin': 'auto', 'background-color': '#f8f8f8', 'padding': '20px', 'border-radius': '10px', 'box-shadow': '0px 0px 10px rgba(0, 0, 0, 0.1)'})\n",
    "\n",
    "\n",
    "\n",
    "def basic_visulation_layout():\n",
    "    return html.Div([\n",
    "        html.H1(\"Basic Visualization Page\", style={'font-family': 'Arial, sans-serif', 'color': '#3366cc'}),\n",
    "        html.P(\"Navigate to other pages using the links below:\", style={'font-family': 'Arial, sans-serif'}),\n",
    "        html.Br(),\n",
    "        dcc.Link('Bar Plot Page', href='/barplot', style={'display': 'block', 'text-decoration': 'none', 'color': '#3366cc', 'margin-bottom': '10px'}),\n",
    "        dcc.Link('Heatmap Page', href='/heatmap', style={'display': 'block', 'text-decoration': 'none', 'color': '#3366cc', 'margin-bottom': '10px'}),\n",
    "    ], style={'width': '60%', 'margin': 'auto', 'background-color': '#f8f8f8', 'padding': '20px', 'border-radius': '10px', 'box-shadow': '0px 0px 10px rgba(0, 0, 0, 0.1)'})\n",
    "\n",
    "def feature_selection_layout():\n",
    "    return html.Div([\n",
    "        html.H1(\"Feature Selection Page\", style={'font-family': 'Arial, sans-serif', 'color': '#3366cc'}),\n",
    "        html.P(\"Navigate to other pages using the links below:\", style={'font-family': 'Arial, sans-serif'}),\n",
    "        dcc.Link('Elastic Net Page', href='/elasticnet', style={'display': 'block', 'text-decoration': 'none', 'color': '#3366cc', 'margin-bottom': '10px'}),\n",
    "        dcc.Link('Random Forest Page', href='/randomforest', style={'display': 'block', 'text-decoration': 'none', 'color': '#3366cc', 'margin-bottom': '10px'}),\n",
    "    ], style={'width': '60%', 'margin': 'auto', 'background-color': '#f8f8f8', 'padding': '20px', 'border-radius': '10px', 'box-shadow': '0px 0px 10px rgba(0, 0, 0, 0.1)'})\n",
    "\n",
    "\n",
    "def class_imbalance_page_layout():\n",
    "    return html.Div([\n",
    "        html.H1(\"Class Imbalance Page\", style={'font-family': 'Arial, sans-serif', 'color': '#3366cc', 'margin-bottom': '20px'}),\n",
    "        html.P(\"Navigate to other pages using the links below:\", style={'font-family': 'Arial, sans-serif', 'margin-bottom': '30px'}),\n",
    "        dcc.Link('t-SNE Page', href='/tsne', style={'display': 'block', 'margin-bottom': '10px', 'color': '#3366cc', 'text-decoration': 'none', 'font-size': '18px'}),\n",
    "        dcc.Link('PCA Page', href='/pca', style={'display': 'block', 'margin-bottom': '10px', 'color': '#3366cc', 'text-decoration': 'none', 'font-size': '18px'}),\n",
    "        dcc.Link('LDA Page', href='/lda', style={'display': 'block', 'margin-bottom': '10px', 'color': '#3366cc', 'text-decoration': 'none', 'font-size': '18px'}),\n",
    "        dcc.Link('KMeans Page', href='/kmeans', style={'display': 'block', 'margin-bottom': '10px', 'color': '#3366cc', 'text-decoration': 'none', 'font-size': '18px'}),\n",
    "    ], style={'width': '60%', 'margin': 'auto', 'background-color': '#f8f8f8', 'padding': '20px', 'border-radius': '10px', 'box-shadow': '0px 0px 10px rgba(0, 0, 0, 0.1)'})\n",
    "\n",
    "\n",
    "# Elastic Net Regression\n",
    "def generate_regularization_path(data):\n",
    "    # Data sampling\n",
    "    # data = data.sample(frac=0.1, random_state=42).\n",
    "\n",
    "    # Data preprocessing\n",
    "    print(\"Dropping correlated features...\")\n",
    "    numerical_features = data.select_dtypes(include=[np.number])\n",
    "    correlation_matrix = numerical_features.corr().abs()\n",
    "    upper_tri = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(np.bool_))\n",
    "    correlated_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
    "    data_filtered = data.drop(correlated_features, axis=1)\n",
    "    print(f\"Correlated features: {correlated_features}\")\n",
    "\n",
    "    # Correlation matrix heatmap\n",
    "    correlation_matrix = data.select_dtypes(include=[np.number]).corr().abs()\n",
    "    fig_corr = px.imshow(correlation_matrix)\n",
    "    fig_corr.update_layout(\n",
    "        title=\"Correlation Matrix Heatmap\",\n",
    "        xaxis_title=\"Features\",\n",
    "        yaxis_title=\"Features\",\n",
    "    )\n",
    "\n",
    "    X = data_filtered.drop(['attack_cat', 'label'], axis=1)\n",
    "    y = data['label']\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    # scaler = StandardScaler()\n",
    "    print(\"Scaling data...\")\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "\n",
    "    n_alphas = 100\n",
    "    # l1_ratios = np.linspace(0.1, 1.0, 5)\n",
    "    selected_l1_ratio = 0.5\n",
    "\n",
    "    # as we are using l1_ratio = 0.5, we can use ElasticNetCV to find the best alpha\n",
    "    # we should be getting the optimal alpha value as 0.000170306\n",
    "    # the alpha values are not generated randomly instead based on a logarithamic spacing of log(alpha_min) to log(alpha_max)\n",
    "    print(\"Searching for best alpha using elastic net...\")\n",
    "    elastic_net_cv = ElasticNetCV(l1_ratio=selected_l1_ratio, n_alphas=n_alphas, cv=5,random_state=42)\n",
    "    elastic_net_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "    print(f\"Best alpha by elastic net: {elastic_net_cv.alpha_}\")\n",
    "    alphas = elastic_net_cv.alphas_\n",
    "    best_alpha = elastic_net_cv.alpha_\n",
    "\n",
    "    print(f\"Alphas size: {alphas.shape}\")\n",
    "\n",
    "    print(\"Fitting model with best alpha...\")\n",
    "    elastic_net = ElasticNet(alpha=best_alpha, l1_ratio=selected_l1_ratio, random_state=0)\n",
    "    elastic_net.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    print(\"Evaluating model...\")\n",
    "    mse_values = elastic_net_cv.mse_path_.T\n",
    "    mse_values_train = []\n",
    "    mse_values_test = []\n",
    "    r2_values_train = []\n",
    "    r2_values_test = []\n",
    "\n",
    "    # Calculating COEFS too\n",
    "    coefs = []\n",
    "\n",
    "    for alpha in tqdm(alphas, desc=\"Evaluation\",leave=False):\n",
    "        elastic_net_tmp = ElasticNet(alpha=alpha, l1_ratio=selected_l1_ratio, random_state=0)\n",
    "        elastic_net_tmp.fit(X_train_scaled, y_train)\n",
    "        y_pred_train = elastic_net_tmp.predict(X_train_scaled)\n",
    "        y_pred_test = elastic_net_tmp.predict(X_test_scaled)\n",
    "        mse_values_train.append(mean_squared_error(y_train, y_pred_train))\n",
    "        mse_values_test.append(mean_squared_error(y_test, y_pred_test))\n",
    "        r2_values_train.append(elastic_net_tmp.score(X_train_scaled, y_train))\n",
    "        r2_values_test.append(elastic_net_tmp.score(X_test_scaled, y_test))\n",
    "        coefs.append(elastic_net_tmp.coef_)\n",
    "    \n",
    "\n",
    "    # Printing Important Features\n",
    "    print(\"Printing important features...\")\n",
    "    important_features = pd.Series(elastic_net.coef_, index=X.columns)\n",
    "\n",
    "    # Important features are the ones with non-zero coefficients\n",
    "    fig_imp_features = px.bar(\n",
    "        x=important_features.index, \n",
    "        y=important_features.values, \n",
    "        labels={'x': 'Features', 'y': 'Importance'}, \n",
    "        title='Important Features categorized by their importance')\n",
    "\n",
    "    important_features = important_features[important_features != 0]\n",
    "    print(f\"Important features: {important_features}\")\n",
    "    print(f\"Lenght of important features: {len(important_features)}\")\n",
    "\n",
    "    # Initially used this to generate the coefs when we chose the l1 ratio as np.linspace(0.1, 1.0, 5)\n",
    "    # but the size was literally (5,100) which is not what we want\n",
    "    # for alpha_values in tqdm(alphas, desc=\"Alpha Values\"):\n",
    "    #     for alpha in tqdm(alpha_values, desc=\"Alphas\", leave=False):\n",
    "    #         elastic_net = ElasticNet(alpha=alpha, l1_ratio=0.5, random_state=0)\n",
    "    #         elastic_net.fit(X_train_scaled, y_train)\n",
    "    #         coefs.append(elastic_net.coef_)\n",
    "\n",
    "    # as the size of alphas is (100,) so we just iterate through it only once\n",
    "\n",
    "    print(\"Coefs has been computed\")\n",
    "    coefs = np.array(coefs)\n",
    "\n",
    "    # Plotting\n",
    "    # fig_mse = go.Figure()\n",
    "\n",
    "    # Version 1\n",
    "    # print(\"Plotting Mean squared error vs alpha...\")\n",
    "    # for each_array in alphas:\n",
    "    #     for each_mse in mse_values:\n",
    "    #         fig_mse = px.line(\n",
    "    #             x=each_array,\n",
    "    #             y=each_mse,\n",
    "    #             title=\"Mean squared error vs alpha\",\n",
    "    #             labels={'x': 'Alpha', 'y': 'Mean squared error'}\n",
    "    #         )\n",
    "\n",
    "    # the size of mse_values is (100,)\n",
    "    # if we choose l1 values as np.linspace(0.1, 1.0, 5) then the size of mse_values will be (5,100,5)\n",
    "    # We transpose it for our convenience\n",
    "    mse_values = elastic_net_cv.mse_path_.T\n",
    "\n",
    "    print(f\"MSE values shape is : {mse_values.shape}\")\n",
    "    print(f\"Alphas shape is : {alphas.shape}\")\n",
    "\n",
    "    # Version 2\n",
    "    print(\"Plotting Mean squared error vs alpha...\")\n",
    "    # fig_mse = go.Figure()\n",
    "    # for i in range(len(mse_values)):\n",
    "    #     fig_mse.add_trace(\n",
    "    #         go.Scatter(\n",
    "    #             x = alphas,\n",
    "    #             y = mse_values[i],\n",
    "    #             name = f\"Fold {i+1}\"\n",
    "    #         )\n",
    "    #     )\n",
    "        \n",
    "    # fig_mse.update_layout(\n",
    "    #     title=\"Mean squared error vs alpha\",\n",
    "    #     xaxis_title=\"Alpha\",\n",
    "    #     yaxis_title=\"Mean squared error\",\n",
    "    # )\n",
    "    fig_mse = go.Figure()\n",
    "    fig_mse.add_trace(\n",
    "        go.Scatter(\n",
    "            x=alphas,\n",
    "            y=mse_values_train,\n",
    "            mode='lines+markers',\n",
    "            name='Train MSE'\n",
    "        )\n",
    "    )\n",
    "    fig_mse.add_trace(\n",
    "        go.Scatter(\n",
    "            x=alphas,\n",
    "            y=mse_values_test,\n",
    "            mode='lines+markers',\n",
    "            name='Test MSE'\n",
    "        )\n",
    "    )\n",
    "    fig_mse.update_layout(\n",
    "        title=\"Mean Squared Error vs alpha\",\n",
    "        xaxis_title=\"Alpha\",\n",
    "        yaxis_title=\"Mean Squared Error\",\n",
    "    )\n",
    "\n",
    "    # Plotting R Squared vs alpha\n",
    "    print(\"Plotting R Squared vs Alpha\")\n",
    "    fig_r2 = go.Figure()\n",
    "    fig_r2.add_trace(\n",
    "        go.Scatter(\n",
    "            x=alphas,\n",
    "            y=r2_values_train,\n",
    "            mode='lines+markers',\n",
    "            name='Train R-squared'\n",
    "        )\n",
    "    )\n",
    "    fig_r2.add_trace(\n",
    "        go.Scatter(\n",
    "            x=alphas,\n",
    "            y=r2_values_test,\n",
    "            mode='lines+markers',\n",
    "            name='Test R-squared'\n",
    "        )\n",
    "    )\n",
    "    fig_r2.update_layout(\n",
    "        title=\"R-squared vs alpha\",\n",
    "        xaxis_title=\"Alpha\",\n",
    "        yaxis_title=\"R-squared\",\n",
    "    )\n",
    "\n",
    "    # Plotting Coefficients vs alpha\n",
    "    # Version 1\n",
    "    print(\"Plotting Coefficients vs alpha...\")\n",
    "    fig_regularization_path = go.Figure()\n",
    "    for i, feature in enumerate(X.columns):\n",
    "        fig_regularization_path.add_trace(\n",
    "            go.Scatter(\n",
    "                x=-np.log10(alphas),\n",
    "                y=coefs[:, i],\n",
    "                name=feature\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig_regularization_path.add_trace(\n",
    "        go.Scatter(\n",
    "            x = [best_alpha],\n",
    "            y=np.linspace(min(np.min(coefs), 0), max(np.max(coefs), 0), 10),\n",
    "            name= 'Best alpha',\n",
    "            mode='lines',\n",
    "            line=dict(color='black', dash='dash'),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig_regularization_path.update_layout(\n",
    "        title=\"Coefficients vs alpha\",\n",
    "        xaxis_title=\"-log(Alpha)\",\n",
    "        yaxis_title=\"Coefficients\",\n",
    "    )\n",
    "\n",
    "    # Version 2\n",
    "    # fig_mse = go.Figure()\n",
    "    # for i in range(len(alphas)):\n",
    "    #     fig_mse.add_trace(\n",
    "    #         go.Scatter(\n",
    "    #             x=alphas[i],\n",
    "    #             y=mse_values[i],\n",
    "    #             name=f\"Fold {i+1}\"\n",
    "    #         )\n",
    "    #     )\n",
    "\n",
    "    # print(\"Plotting Coefficients vs alpha...\")\n",
    "    # fig_regularization_path = go.Figure()\n",
    "    # for i, feature in enumerate(X.columns):\n",
    "    #     fig_regularization_path.add_trace(\n",
    "    #         go.Scatter(\n",
    "    #             x=alphas,\n",
    "    #             y=coefs[:, i],\n",
    "    #             name=feature\n",
    "    #         )\n",
    "    #     )\n",
    "    \n",
    "    # fig_regularization_path.add_trace(\n",
    "    #     go.Scatter(\n",
    "    #         x = [best_alpha],\n",
    "    #         y=np.linspace(min(np.min(coefs), 0), max(np.max(coefs), 0), 10),\n",
    "    #         name= 'Best alpha',\n",
    "    #         mode='lines',\n",
    "    #         line=dict(color='black', dash='dash'),\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "    return fig_mse, fig_regularization_path, fig_r2, fig_imp_features\n",
    "    \n",
    "# Elastic Net Layout\n",
    "def elastic_net_layout():\n",
    "    return html.Div(children=[\n",
    "        html.H1(\"Elastic Net Plots\",style={'textAlign': 'center', 'font-family': 'Arial, sans-serif', 'color': '#3366cc', 'margin-bottom': '20px'}),\n",
    "        html.Div(\n",
    "            dcc.Loading(\n",
    "                id=\"loading-elastic-net\",\n",
    "                type=\"circle\",\n",
    "                children=[\n",
    "                    dcc.Graph(id='elastic-net-mse-plot'),\n",
    "                ]\n",
    "            )\n",
    "        ),\n",
    "\n",
    "        html.Div(\n",
    "            dcc.Loading(\n",
    "                id=\"loading-regularization-path\",\n",
    "                type=\"circle\",\n",
    "                children=[\n",
    "                    dcc.Graph(id='elastic-net-coef-plot'),\n",
    "                ]\n",
    "            )\n",
    "        ),\n",
    "\n",
    "        html.Div(\n",
    "            dcc.Loading(\n",
    "                id=\"loading-correration-matrix\",\n",
    "                type=\"circle\",\n",
    "                children=[\n",
    "                    dcc.Graph(id='correration-matrix-plot'),\n",
    "                ]\n",
    "            )\n",
    "        ),\n",
    "\n",
    "        html.Div(\n",
    "            dcc.Loading(\n",
    "                id=\"loading-important-features\",\n",
    "                type=\"circle\",\n",
    "                children=[\n",
    "                    dcc.Graph(id='important-features-plot'),\n",
    "                ]\n",
    "            )\n",
    "        ),\n",
    "    ], style={'margin': 'auto', 'background-color': '#f8f8f8', 'padding': '20px', 'border-radius': '10px', 'box-shadow': '0px 0px 10px rgba(0, 0, 0, 0.1)'})\n",
    "\n",
    "# Regularization Path Callbacks\n",
    "@app.callback(\n",
    "    [Output('elastic-net-mse-plot', 'figure'),\n",
    "     Output('elastic-net-coef-plot', 'figure'),\n",
    "     Output('correration-matrix-plot', 'figure'),\n",
    "     Output('important-features-plot', 'figure')],\n",
    "    [Input('url', 'pathname')],\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def update_regularization_path(pathname):\n",
    "    if pathname == '/elasticnet':\n",
    "        print(\"-- Entered here --\")\n",
    "        mse_plot,coef_plot,fig_corr,imp_features = generate_regularization_path(train_df)\n",
    "        print(\"-- Exited here --\")\n",
    "        return mse_plot,coef_plot,fig_corr,imp_features\n",
    "    else:\n",
    "        return dash.no_update\n",
    "    \n",
    "# Random Forest Classifier\n",
    "def generate_feature_importance_path(data):\n",
    "    numerical_features = data.select_dtypes(include=[np.number])\n",
    "    correlation_matrix = numerical_features.corr().abs()\n",
    "    upper_tri = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(np.bool_))\n",
    "    correlated_features = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
    "    data_filtered = data.drop(correlated_features, axis=1)\n",
    "    X = data_filtered.drop(['attack_cat', 'label'], axis=1)\n",
    "    y = data['label']\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    # If we required we can perform necessary operations on X_test and y_test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    important_features = rf.feature_importances_\n",
    "    print(f\"Important features: {important_features}\")\n",
    "    print(f\"Lenght of important features: {len(important_features)}\")\n",
    "\n",
    "    # Evaluation metrics\n",
    "    # y_pred = rf.predict(X_train)\n",
    "    # accuracy = accuracy_score(y, y_pred)\n",
    "    # precision = precision_score(y, y_pred)\n",
    "    # recall = recall_score(y, y_pred)\n",
    "    # f1 = f1_score(y, y_pred)\n",
    "    # print(f\"Accuracy: {accuracy}\")\n",
    "    # print(f\"Precision: {precision}\")\n",
    "    # print(f\"Recall: {recall}\")\n",
    "    # print(f\"F1: {f1}\")\n",
    "\n",
    "\n",
    "    fig_rf = go.Figure()\n",
    "    fig_rf.add_trace(\n",
    "        go.Bar(\n",
    "            x=X.columns,\n",
    "            y=important_features,\n",
    "            name=\"Feature Importance\"\n",
    "        )\n",
    "    )\n",
    "    fig_rf.update_layout(\n",
    "        title=\"Feature Importance based on Random Forest Classifier\",\n",
    "        xaxis_title=\"Features\",\n",
    "        yaxis_title=\"Importance\",\n",
    "    )\n",
    "\n",
    "    return fig_rf\n",
    "\n",
    "# Random Forest Layout\n",
    "def random_forest_layout():\n",
    "    return html.Div([\n",
    "        html.H1(\"Random Forest Plots\",style={'textAlign': 'center', 'font-family': 'Arial, sans-serif', 'color': '#3366cc', 'margin-bottom': '20px'}),\n",
    "        dcc.Loading(\n",
    "            id=\"loading-random-forest\",\n",
    "            type=\"circle\",\n",
    "            children=[dcc.Graph(id='random-forest-plot')],\n",
    "        )\n",
    "    ], style={'margin': 'auto', 'background-color': '#f8f8f8', 'padding': '20px', 'border-radius': '10px', 'box-shadow': '0px 0px 10px rgba(0, 0, 0, 0.1)'})\n",
    "\n",
    "# Random Forest callbacks\n",
    "@app.callback(\n",
    "    Output('random-forest-plot','figure'),\n",
    "    [Input('url', 'pathname')],\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def update_random_forest_plot(pathname):\n",
    "    if pathname == '/randomforest':\n",
    "        rf_plot = generate_feature_importance_path(train_df)\n",
    "        return rf_plot\n",
    "    else:\n",
    "        return dash.no_update\n",
    "    \n",
    "# KMeans Clustering Layout\n",
    "def kmeans_layout():\n",
    "    return html.Div([\n",
    "        html.H1(\"K-Means Plots\",style={'textAlign': 'center', 'font-family': 'Arial, sans-serif', 'color': '#3366cc', 'margin-bottom': '20px'}),\n",
    "        dcc.Loading(\n",
    "            id=\"loading-kmeans\",\n",
    "            type=\"circle\",\n",
    "            children=[\n",
    "                dcc.Graph(id='kmeans-plot'),\n",
    "            ]\n",
    "        ),\n",
    "    \n",
    "    ], style={'margin': 'auto', 'background-color': '#f8f8f8', 'padding': '20px', 'border-radius': '10px', 'box-shadow': '0px 0px 10px rgba(0, 0, 0, 0.1)'})\n",
    "\n",
    "# KMeans Clustering Callbacks\n",
    "@app.callback(\n",
    "    Output('kmeans-plot', 'figure'),\n",
    "    [Input('url', 'pathname')],\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def update_kmeans_plot(pathname):\n",
    "    if pathname == '/kmeans':\n",
    "        X = apply_pca(train_df.copy(), 2)\n",
    "        labels = train_df['attack_cat']\n",
    "\n",
    "        shrunken_centroids = NearestCentroid(shrink_threshold=None)\n",
    "        shrunken_centroids.fit(X, labels)\n",
    "        class_centroids = shrunken_centroids.centroids_\n",
    "        kmeans = KMeans(n_clusters=len(class_centroids), init=class_centroids, n_init=1, max_iter=1)\n",
    "        kmeans.fit(X)\n",
    "\n",
    "        cluster_centers = kmeans.cluster_centers_\n",
    "        # cluster_labels = kmeans.labels_\n",
    "        print(f\"Cluster centers: {cluster_centers}\")\n",
    "        # intercluster_distances = euclidean_distances(cluster_centers, cluster_centers)\n",
    "        cluster_sizes = np.bincount(kmeans.labels_)\n",
    "        print(f\"Cluster sizes: {cluster_sizes}\")\n",
    "\n",
    "        fig = go.Figure()\n",
    "        for i,(x,y) in enumerate(cluster_centers[:, :2]):\n",
    "            center = go.Scatter(\n",
    "                x=[x],\n",
    "                y=[y],\n",
    "                mode='text',\n",
    "                text=[str(i)],\n",
    "                marker=dict(size=5, color='rgba(255,0,0,1)'),\n",
    "                showlegend=False,\n",
    "            )\n",
    "            fig.add_trace(center)\n",
    "\n",
    "        # We are using the cluster size to plot the circle around the center\n",
    "        for i, (x, y) in enumerate(cluster_centers[:, :2]):\n",
    "            circle = go.Scatter(\n",
    "                x=[x],\n",
    "                y=[y],\n",
    "                mode='markers',\n",
    "                marker=dict(size=np.sqrt(cluster_sizes[i]), color='rgba(155,155,223,0.56)'),\n",
    "                name=f'Cluster {i}',\n",
    "            )\n",
    "            fig.add_trace(circle)\n",
    "\n",
    "        # Update layout for 2D plot\n",
    "        fig.update_layout(\n",
    "            title='K-means Cluster Analysis: Size, Spread, and Overlap',\n",
    "            xaxis=dict(title='First Dimension',showgrid=False, showticklabels=False),\n",
    "            yaxis=dict(title='Second dimension', showticklabels=False, showgrid=False),\n",
    "            height = 800,\n",
    "        )\n",
    "\n",
    "        return fig\n",
    "\n",
    "    else:\n",
    "        return dash.no_update\n",
    "    \n",
    "\n",
    "\n",
    "def run_dash_app():\n",
    "    app.run_server(debug=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_dash_app()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VIZ_PROJECT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
